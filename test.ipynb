{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa30ac37",
   "metadata": {},
   "source": [
    "Setup & Token (run first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b9ad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repos will be synced into: C:\\Users\\admin\\DOWNLOAD_REPOS\\github_repos\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 1: Setup & Token\n",
    "# =========================\n",
    "# What this cell does:\n",
    "# - Imports libraries used later\n",
    "# - Lets you paste ONLY your GitHub token\n",
    "# - Sets base download folder (change if you want)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import shutil\n",
    "import pathlib\n",
    "import subprocess\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import requests\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# PASTE YOUR TOKEN HERE (string) â€” REQUIRED. Do not print it anywhere.\n",
    "GITHUB_TOKEN = \"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\"  # <-- replace with your token\n",
    "# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "# Optional: You can also set via environment variable if you prefer:\n",
    "# os.environ[\"GITHUB_TOKEN\"] = GITHUB_TOKEN\n",
    "\n",
    "# Base directory where repos will be cloned/updated (change if you like)\n",
    "BASE_DIR = pathlib.Path(\"./github_repos\").resolve()\n",
    "\n",
    "# Fast toggle: include forks? (True/False)\n",
    "INCLUDE_FORKS = True\n",
    "\n",
    "# Fast toggle: include archived repos? (True/False)\n",
    "INCLUDE_ARCHIVED = True\n",
    "\n",
    "# Parallelism for cloning/pulling\n",
    "MAX_WORKERS = max(4, (os.cpu_count() or 4) * 2)\n",
    "\n",
    "# Git executable name (change if needed, e.g., \"git.exe\" on Windows if PATH issues)\n",
    "GIT_BIN = \"git\"\n",
    "\n",
    "# Fail early if token missing\n",
    "if not GITHUB_TOKEN or not GITHUB_TOKEN.strip():\n",
    "    raise RuntimeError(\"GITHUB_TOKEN is empty. Please paste your token in Cell 1.\")\n",
    "\n",
    "# Create base directory\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Repos will be synced into: {BASE_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb66d699",
   "metadata": {},
   "source": [
    "Step 2 â€” GitHub API helpers (no owner needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83cf86e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git is available.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 2: Helper functions\n",
    "# =========================\n",
    "\n",
    "def _mask_token(text: str) -> str:\n",
    "    \"\"\"Mask appearance of token in any string to avoid accidental prints.\"\"\"\n",
    "    if not text:\n",
    "        return text\n",
    "    # Simple mask if token accidentally shows up\n",
    "    return text.replace(GITHUB_TOKEN, \"***TOKEN***\")\n",
    "\n",
    "def run_cmd(cmd, cwd=None, timeout=1800):\n",
    "    \"\"\"\n",
    "    Run a shell command safely without printing the token.\n",
    "    Returns (returncode, stdout, stderr).\n",
    "    \"\"\"\n",
    "    # IMPORTANT: Never print cmd since it can contain the token in the URL.\n",
    "    try:\n",
    "        p = subprocess.run(\n",
    "            cmd,\n",
    "            cwd=str(cwd) if cwd else None,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            timeout=timeout,\n",
    "            check=False,\n",
    "            text=True\n",
    "        )\n",
    "        return p.returncode, p.stdout, p.stderr\n",
    "    except FileNotFoundError:\n",
    "        raise RuntimeError(\n",
    "            f\"Command not found: {cmd[0]}. Make sure '{GIT_BIN}' is installed and in PATH.\"\n",
    "        )\n",
    "\n",
    "def ensure_git_available():\n",
    "    \"\"\"Check that git CLI is available.\"\"\"\n",
    "    code, out, err = run_cmd([GIT_BIN, \"--version\"])\n",
    "    if code != 0:\n",
    "        raise RuntimeError(\n",
    "            f\"'git' not available. Install Git and ensure it's on PATH. Details:\\n{err}\"\n",
    "        )\n",
    "\n",
    "def auth_clone_url(plain_clone_url: str, token: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert 'https://github.com/owner/repo.git' to\n",
    "    'https://x-access-token:{token}@github.com/owner/repo.git'\n",
    "    \"\"\"\n",
    "    # We always force https+token auth. Do not support ssh in this script (by design).\n",
    "    u = urlparse(plain_clone_url)\n",
    "    # For GitHub, netloc is 'github.com'; insert token as user:pass\n",
    "    # Using 'x-access-token' as username avoids exposing 'ghp_' pattern in process listings.\n",
    "    return f\"https://x-access-token:{token}@{u.netloc}{u.path}\"\n",
    "\n",
    "def repo_local_path(base_dir: pathlib.Path, full_name: str) -> pathlib.Path:\n",
    "    \"\"\"\n",
    "    Map 'owner/repo' to local path 'base_dir/owner/repo'.\n",
    "    We do NOT ask you for owner; we just use what API returns for uniqueness.\n",
    "    \"\"\"\n",
    "    owner, repo = full_name.split(\"/\", 1)\n",
    "    return base_dir / owner / repo\n",
    "\n",
    "def human_repo(r):\n",
    "    \"\"\"Minimal printable identity for debug (never shows token).\"\"\"\n",
    "    return f\"{r.get('full_name')} (private={r.get('private')}, fork={r.get('fork')}, archived={r.get('archived')})\"\n",
    "\n",
    "ensure_git_available()\n",
    "print(\"Git is available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0f1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2692242f",
   "metadata": {},
   "source": [
    "ðŸ§ª Cell 3 â€” GitHub API: Fetch all repos you can access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbea4bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered 11 repos to sync.\n",
      " - Tushar-Padole/Alphabets-Recognition (private=False, fork=False, archived=False)\n",
      " - Tushar-Padole/Cat-Vs-Dog (private=True, fork=False, archived=False)\n",
      " - Tushar-Padole/Digit-Recognizer (private=True, fork=False, archived=False)\n",
      " - Tushar-Padole/House-Prices-Prediction (private=True, fork=False, archived=False)\n",
      " - Tushar-Padole/Next-Word-Predictor-Sherlock-Holmes- (private=True, fork=False, archived=False)\n",
      " - Tushar-Padole/Recipe_making_recommender (private=False, fork=False, archived=False)\n",
      " - Tushar-Padole/Summer-Olympic-Games-Analysis-1896-2024- (private=False, fork=False, archived=False)\n",
      " - Tushar-Padole/test_git_pro (private=False, fork=False, archived=False)\n",
      " - Tushar-Padole/Titanic-survival-prediction (private=False, fork=False, archived=False)\n",
      " - Tushar-Padole/Titanic-survival-prediction_old (private=True, fork=False, archived=False)\n",
      " - Tushar-Padole/TripC_Bike (private=False, fork=False, archived=False)\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# Cell 3: List all repos (public + private)\n",
    "# =========================================\n",
    "# This cell uses ONLY your token (no owner input) to list repos you can access:\n",
    "# - Your own repos\n",
    "# - Private repos you own\n",
    "# - Repos you collaborate on\n",
    "# - Organization repos you can access\n",
    "# It handles pagination (no artificial limits).\n",
    "\n",
    "def list_all_repos(token: str,\n",
    "                   include_forks: bool = True,\n",
    "                   include_archived: bool = True) -> list:\n",
    "    \"\"\"\n",
    "    Returns a list of repository dicts (GitHub API format).\n",
    "    Uses /user/repos so no owner is needed.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"token {token}\",\n",
    "        \"Accept\": \"application/vnd.github+json\",\n",
    "        \"X-GitHub-Api-Version\": \"2022-11-28\",\n",
    "        \"User-Agent\": \"gh-sync-script\"\n",
    "    }\n",
    "\n",
    "    # Affiliation covers repos you own, collaborate on, and org membership repos.\n",
    "    # visibility=all -> public+private\n",
    "    # per_page=100 -> max per page, then paginate until empty.\n",
    "    base_url = \"https://api.github.com/user/repos\"\n",
    "    params = {\n",
    "        \"visibility\": \"all\",\n",
    "        \"affiliation\": \"owner,collaborator,organization_member\",\n",
    "        \"per_page\": 100,\n",
    "        \"page\": 1\n",
    "    }\n",
    "\n",
    "    all_repos = []\n",
    "    while True:\n",
    "        resp = requests.get(base_url, headers=headers, params=params, timeout=60)\n",
    "        if resp.status_code == 403 and \"rate limit\" in resp.text.lower():\n",
    "            raise RuntimeError(\"Rate limited by GitHub. Try again later or use a fresh token with higher limits.\")\n",
    "        if resp.status_code >= 400:\n",
    "            raise RuntimeError(f\"GitHub API error {resp.status_code}: {resp.text}\")\n",
    "        page_repos = resp.json()\n",
    "        if not page_repos:\n",
    "            break\n",
    "        for r in page_repos:\n",
    "            if not include_forks and r.get(\"fork\"):\n",
    "                continue\n",
    "            if not include_archived and r.get(\"archived\"):\n",
    "                continue\n",
    "            all_repos.append(r)\n",
    "        params[\"page\"] += 1\n",
    "\n",
    "    # Sort by full_name for stable processing order\n",
    "    all_repos.sort(key=lambda r: r.get(\"full_name\", \"\").lower())\n",
    "    return all_repos\n",
    "\n",
    "repos = list_all_repos(GITHUB_TOKEN, INCLUDE_FORKS, INCLUDE_ARCHIVED)\n",
    "print(f\"Discovered {len(repos)} repos to sync.\")\n",
    "# Optional: peek at a few names (safe to print)\n",
    "for r in repos[:11]:\n",
    "    print(\" -\", human_repo(r))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978944ff",
   "metadata": {},
   "source": [
    "ðŸ§ª Cell 4 â€” Clone or Update a Single Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f55f103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# Cell 4: Clone / Update one repository\n",
    "# =======================================\n",
    "# This cell defines functions to clone a missing repo or update an existing one.\n",
    "# It uses HTTPS with token auth. Do NOT print the command since it may contain token in URL.\n",
    "\n",
    "def clone_repo(r: dict, token: str, base_dir: pathlib.Path) -> tuple:\n",
    "    \"\"\"\n",
    "    Clone a repository that doesn't exist locally.\n",
    "    Returns (success:bool, message:str)\n",
    "    \"\"\"\n",
    "    full_name = r[\"full_name\"]\n",
    "    dest = repo_local_path(base_dir, full_name)\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    url = auth_clone_url(r[\"clone_url\"], token)\n",
    "\n",
    "    # We do a full clone (no depth limit) to honor \"no limit\" requirement.\n",
    "    cmd = [GIT_BIN, \"clone\", \"--recursive\", url, str(dest)]\n",
    "    code, out, err = run_cmd(cmd)\n",
    "    if code == 0:\n",
    "        # Optional: initialize submodules (clone --recursive should already do this)\n",
    "        sm_code, sm_out, sm_err = run_cmd([GIT_BIN, \"-C\", str(dest), \"submodule\", \"update\", \"--init\", \"--recursive\", \"--jobs\", \"4\"])\n",
    "        if sm_code != 0:\n",
    "            return False, f\"[CLONE OK][SUBMODULE WARN] {full_name}: {sm_err.strip()}\"\n",
    "        return True, f\"[CLONE OK] {full_name}\"\n",
    "    else:\n",
    "        # If directory got partially created, clean it to avoid broken state\n",
    "        if dest.exists() and not (dest / \".git\").exists():\n",
    "            try:\n",
    "                shutil.rmtree(dest)\n",
    "            except Exception:\n",
    "                pass\n",
    "        return False, f\"[CLONE FAIL] {full_name}: {err.strip() or out.strip()}\"\n",
    "\n",
    "def update_repo(r: dict, token: str, base_dir: pathlib.Path) -> tuple:\n",
    "    \"\"\"\n",
    "    Update an existing local repo by fetching/pulling latest commits.\n",
    "    Returns (success:bool, message:str)\n",
    "    \"\"\"\n",
    "    full_name = r[\"full_name\"]\n",
    "    dest = repo_local_path(base_dir, full_name)\n",
    "    url = auth_clone_url(r[\"clone_url\"], token)\n",
    "\n",
    "    if not (dest / \".git\").exists():\n",
    "        return clone_repo(r, token, base_dir)\n",
    "\n",
    "    # Ensure 'origin' remote uses an authenticated URL (important for private repos)\n",
    "    code, out, err = run_cmd([GIT_BIN, \"-C\", str(dest), \"remote\", \"set-url\", \"origin\", url])\n",
    "    if code != 0:\n",
    "        return False, f\"[REMOTE SET-URL FAIL] {full_name}: {err.strip() or out.strip()}\"\n",
    "\n",
    "    # Track all branches to keep everything current\n",
    "    run_cmd([GIT_BIN, \"-C\", str(dest), \"remote\", \"set-branches\", \"origin\", \"*\"])\n",
    "\n",
    "    # Fetch all refs and prune deleted ones, plus tags\n",
    "    code, out, err = run_cmd([GIT_BIN, \"-C\", str(dest), \"fetch\", \"--all\", \"--prune\", \"--tags\"])\n",
    "    if code != 0:\n",
    "        return False, f\"[FETCH FAIL] {full_name}: {err.strip() or out.strip()}\"\n",
    "\n",
    "    # Ensure we're on default branch (helps if repo was checked out elsewhere)\n",
    "    default_branch = r.get(\"default_branch\") or \"main\"\n",
    "    # Checkout default branch (ignore errors if already on it)\n",
    "    run_cmd([GIT_BIN, \"-C\", str(dest), \"checkout\", default_branch])\n",
    "\n",
    "    # Fast-forward pull on the default branch\n",
    "    code, out, err = run_cmd([GIT_BIN, \"-C\", str(dest), \"pull\", \"--ff-only\"])\n",
    "    if code != 0:\n",
    "        # If fast-forward fails because of local changes, try stash+pull (non-destructive)\n",
    "        # NOTE: If you have local edits, they will be stashed.\n",
    "        run_cmd([GIT_BIN, \"-C\", str(dest), \"stash\", \"push\", \"-u\", \"-m\", \"auto-stash-before-ff-pull\"])\n",
    "        code2, out2, err2 = run_cmd([GIT_BIN, \"-C\", str(dest), \"pull\", \"--ff-only\"])\n",
    "        if code2 != 0:\n",
    "            return False, f\"[PULL FAIL] {full_name}: {err2.strip() or out2.strip()}\"\n",
    "\n",
    "    # Update submodules if any\n",
    "    run_cmd([GIT_BIN, \"-C\", str(dest), \"submodule\", \"update\", \"--init\", \"--recursive\", \"--jobs\", \"4\"])\n",
    "\n",
    "    return True, f\"[UPDATE OK] {full_name}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04503bda",
   "metadata": {},
   "source": [
    "ðŸ§ª Cell 5 â€” Sync All Repos (parallel, fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa33a314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to sync. Run the next cell to execute a one-shot sync.\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# Cell 5: Sync ALL repos in parallel\n",
    "# ======================================\n",
    "# - Detects whether repo exists locally\n",
    "# - Clones if missing, otherwise fetches updates\n",
    "# - Runs in parallel for speed\n",
    "\n",
    "def sync_all_repos(repos: list, token: str, base_dir: pathlib.Path, max_workers: int = MAX_WORKERS):\n",
    "    to_process = []\n",
    "    for r in repos:\n",
    "        local = repo_local_path(base_dir, r[\"full_name\"])\n",
    "        exists = (local / \".git\").exists()\n",
    "        to_process.append((exists, r))\n",
    "\n",
    "    results = {\"ok\": 0, \"fail\": 0, \"messages\": []}\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        future_to_repo = {}\n",
    "        for exists, r in to_process:\n",
    "            if exists:\n",
    "                future = ex.submit(update_repo, r, token, base_dir)\n",
    "            else:\n",
    "                future = ex.submit(clone_repo, r, token, base_dir)\n",
    "            future_to_repo[future] = r\n",
    "\n",
    "        for fut in as_completed(future_to_repo):\n",
    "            r = future_to_repo[fut]\n",
    "            try:\n",
    "                ok, msg = fut.result()\n",
    "                results[\"messages\"].append(msg)\n",
    "                if ok:\n",
    "                    results[\"ok\"] += 1\n",
    "                else:\n",
    "                    results[\"fail\"] += 1\n",
    "            except Exception as e:\n",
    "                results[\"fail\"] += 1\n",
    "                results[\"messages\"].append(f\"[ERROR] {r.get('full_name')}: {e}\")\n",
    "\n",
    "    # Print a concise summary (no secrets)\n",
    "    print(f\"\\n==== Sync Summary ====\")\n",
    "    print(f\"Total repos: {len(repos)}\")\n",
    "    print(f\"OK: {results['ok']}  |  FAIL: {results['fail']}\")\n",
    "    if results[\"fail\"]:\n",
    "        print(\"Some failures occurred. See messages below:\")\n",
    "    # Print last 30 messages to avoid too much output\n",
    "    for m in results[\"messages\"][-30:]:\n",
    "        print(m)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run a one-shot sync now (optional; or run in next cell)\n",
    "print(\"Ready to sync. Run the next cell to execute a one-shot sync.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4af5a3",
   "metadata": {},
   "source": [
    "ðŸ§ª Cell 6 â€” One-Shot Sync Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5f16edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Sync Summary ====\n",
      "Total repos: 11\n",
      "OK: 11  |  FAIL: 0\n",
      "[UPDATE OK] Tushar-Padole/Recipe_making_recommender\n",
      "[UPDATE OK] Tushar-Padole/Alphabets-Recognition\n",
      "[UPDATE OK] Tushar-Padole/TripC_Bike\n",
      "[UPDATE OK] Tushar-Padole/Titanic-survival-prediction\n",
      "[UPDATE OK] Tushar-Padole/test_git_pro\n",
      "[UPDATE OK] Tushar-Padole/Titanic-survival-prediction_old\n",
      "[UPDATE OK] Tushar-Padole/Digit-Recognizer\n",
      "[UPDATE OK] Tushar-Padole/House-Prices-Prediction\n",
      "[UPDATE OK] Tushar-Padole/Next-Word-Predictor-Sherlock-Holmes-\n",
      "[UPDATE OK] Tushar-Padole/Cat-Vs-Dog\n",
      "[UPDATE OK] Tushar-Padole/Summer-Olympic-Games-Analysis-1896-2024-\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# Cell 6: One-shot sync now\n",
    "# ======================================\n",
    "# This will:\n",
    "# 1) Re-list repos (in case new ones were added)\n",
    "# 2) Clone missing repos and update existing ones\n",
    "\n",
    "repos = list_all_repos(GITHUB_TOKEN, INCLUDE_FORKS, INCLUDE_ARCHIVED)\n",
    "result = sync_all_repos(repos, GITHUB_TOKEN, BASE_DIR, MAX_WORKERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f09f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fire_Fighting_Talking",
   "language": "python",
   "name": "fire_fighting_talking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
